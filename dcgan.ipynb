{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# DCGAN in PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "        @article{Chakraborty_2021_Training_DCGAN,\n",
        "        author = {Devjyoti Chakraborty},\n",
        "        title = {Training a {DCGAN} in {PyTorch}},\n",
        "        journal = {PyImageSearch},\n",
        "        year = {2021},\n",
        "        note = {https://pyimagesearch.com/2021/10/25/training-a-dcgan-in-pytorch/},\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8yZr7pAjGdhA"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from IPython.display import Image\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "from sklearn.utils import shuffle\n",
        "from imutils import build_montages\n",
        "from torch.optim import Adam\n",
        "from torch.nn import BCELoss\n",
        "from torch.nn import ConvTranspose2d\n",
        "from torch.nn import BatchNorm2d\n",
        "from torch.nn import Conv2d\n",
        "from torch.nn import Linear\n",
        "from torch.nn import LeakyReLU\n",
        "from torch.nn import ReLU\n",
        "from torch.nn import Tanh\n",
        "from torch.nn import Sigmoid\n",
        "from torch import flatten\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch\n",
        "import cv2\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgqrR4tpHIjZ"
      },
      "outputs": [],
      "source": [
        "# Replace argument parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "\t\"output\": \"output\",\n",
        "    \"epochs\": 20,\n",
        "    \"batch-size\": 128,\n",
        "    \"gif\": \"output.gif\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLWfCCT6G407"
      },
      "source": [
        "### Define the Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJaCNlDDRz6d"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "\tdef __init__(self, inputDim=100, outputDim=512, outputChannels=1):\n",
        "\t\tsuper(Generator, self).__init__()\n",
        "\n",
        "\t\t# first set of CONVT => RELU => BN\n",
        "\t\tself.ct1 = ConvTranspose2d(in_channels=inputDim,\n",
        "\t\t\tout_channels=128, kernel_size=4, stride=2, padding=0,\n",
        "\t\t\tbias=False)\n",
        "\t\tself.relu1 = ReLU()\n",
        "\t\tself.batchNorm1 = BatchNorm2d(128)\n",
        "\n",
        "\t\t# second set of CONVT => RELU => BN\n",
        "\t\tself.ct2 = ConvTranspose2d(in_channels=128, out_channels=64,\n",
        "\t\t\t\t\tkernel_size=3, stride=2, padding=1, bias=False)\n",
        "\t\tself.relu2 = ReLU()\n",
        "\t\tself.batchNorm2 = BatchNorm2d(64)\n",
        "\n",
        "\t\t# last set of CONVT => RELU => BN\n",
        "\t\tself.ct3 = ConvTranspose2d(in_channels=64, out_channels=32,\n",
        "\t\t\t\t\tkernel_size=4, stride=2, padding=1, bias=False)\n",
        "\t\tself.relu3 = ReLU()\n",
        "\t\tself.batchNorm3 = BatchNorm2d(32)\n",
        "\n",
        "\t\t# apply another upsample and transposed convolution, but\n",
        "\t\t# this time output the TANH activation\n",
        "\t\tself.ct4 = ConvTranspose2d(in_channels=32,\n",
        "\t\t\tout_channels=outputChannels, kernel_size=4, stride=2,\n",
        "\t\t\tpadding=1, bias=False)\n",
        "\t\tself.tanh = Tanh()\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# pass the input through our first set of CONVT => RELU => BN\n",
        "\t\t# layers\n",
        "\t\tx = self.ct1(x)\n",
        "\t\tx = self.relu1(x)\n",
        "\t\tx = self.batchNorm1(x)\n",
        "\n",
        "\t\t# pass the output from previous layer through our second\n",
        "\t\t# CONVT => RELU => BN layer set\n",
        "\t\tx = self.ct2(x)\n",
        "\t\tx = self.relu2(x)\n",
        "\t\tx = self.batchNorm2(x)\n",
        "\n",
        "\t\t# pass the output from previous layer through our last set\n",
        "\t\t# of CONVT => RELU => BN layers\n",
        "\t\tx = self.ct3(x)\n",
        "\t\tx = self.relu3(x)\n",
        "\t\tx = self.batchNorm3(x)\n",
        "\n",
        "\t\t# pass the output from previous layer through CONVT2D => TANH\n",
        "\t\t# layers to get our output\n",
        "\t\tx = self.ct4(x)\n",
        "\t\toutput = self.tanh(x)\n",
        "\n",
        "\t\t# return the output\n",
        "\t\treturn output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXgDCG3vG_ve"
      },
      "source": [
        "### Define the Disciminator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNMa2lw3G_j5"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "\tdef __init__(self, depth, alpha=0.2):\n",
        "\t\tsuper(Discriminator, self).__init__()\n",
        "\n",
        "\t\t# first set of CONV => RELU layers\n",
        "\t\tself.conv1 = Conv2d(in_channels=depth, out_channels=32,\n",
        "\t\t\t\tkernel_size=4, stride=2, padding=1)\n",
        "\t\tself.leakyRelu1 = LeakyReLU(alpha, inplace=True)\n",
        "\n",
        "\t\t# second set of CONV => RELU layers\n",
        "\t\tself.conv2 = Conv2d(in_channels=32, out_channels=64, kernel_size=4,\n",
        "\t\t\t\tstride=2, padding=1)\n",
        "\t\tself.leakyRelu2 = LeakyReLU(alpha, inplace=True)\n",
        "\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tself.fc1 = Linear(in_features=3136, out_features=512)\n",
        "\t\tself.leakyRelu3 = LeakyReLU(alpha, inplace=True)\n",
        "\n",
        "\t\t# sigmoid layer outputting a single value\n",
        "\t\tself.fc2 = Linear(in_features=512, out_features=1)\n",
        "\t\tself.sigmoid = Sigmoid()\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# pass the input through first set of CONV => RELU layers\n",
        "\t\tx = self.conv1(x)\n",
        "\t\tx = self.leakyRelu1(x)\n",
        "\n",
        "\t\t# pass the output from the previous layer through our second\n",
        "\t\t# set of CONV => RELU layers\n",
        "\t\tx = self.conv2(x)\n",
        "\t\tx = self.leakyRelu2(x)\n",
        "\n",
        "\t\t# flatten the output from the previous layer and pass it\n",
        "\t\t# through our first (and only) set of FC => RELU layers\n",
        "\t\tx = flatten(x, 1)\n",
        "\t\tx = self.fc1(x)\n",
        "\t\tx = self.leakyRelu3(x)\n",
        "\n",
        "\t\t# pass the output from the previous layer through our sigmoid\n",
        "\t\t# layer outputting a single value\n",
        "\t\tx = self.fc2(x)\n",
        "\t\toutput = self.sigmoid(x)\n",
        "\n",
        "\t\t# return the output\n",
        "\t\treturn output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MtYB5H0HqIi"
      },
      "source": [
        "### Custom weight initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyoniDkXHqZl"
      },
      "outputs": [],
      "source": [
        "# custom weights initialization called on generator and discriminator\n",
        "def weights_init(model):\n",
        "\t# get the class name\n",
        "\tclassname = model.__class__.__name__\n",
        "\n",
        "\t# check if the classname contains the word \"conv\"\n",
        "\tif classname.find(\"Conv\") != -1:\n",
        "\t\t# intialize the weights from normal distribution\n",
        "\t\tnn.init.normal_(model.weight.data, 0.0, 0.02)\n",
        "\n",
        "\t# otherwise, check if the name contains the word \"BatcnNorm\"\n",
        "\telif classname.find(\"BatchNorm\") != -1:\n",
        "\t\t# intialize the weights from normal distribution and set the\n",
        "\t\t# bias to 0\n",
        "\t\tnn.init.normal_(model.weight.data, 1.0, 0.02)\n",
        "\t\tnn.init.constant_(model.bias.data, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xJMLVTOHuH4"
      },
      "source": [
        "### Building the data pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC4PhWFtGnkJ"
      },
      "outputs": [],
      "source": [
        "# store the epochs and batch size in convenience variables\n",
        "NUM_EPOCHS = args[\"epochs\"]\n",
        "BATCH_SIZE = args[\"batch-size\"]\n",
        "\n",
        "# set the device we will be using\n",
        "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# define data transforms\n",
        "dataTransforms = transforms.Compose([\n",
        "\ttransforms.ToTensor(),\n",
        "\ttransforms.Normalize((0.5), (0.5))]\n",
        ")\n",
        "\n",
        "# load the MNIST dataset and stack the training and testing data\n",
        "# points so we have additional training data\n",
        "print(\"[INFO] loading DeepWeeds dataset...\")\n",
        "trainData = MNIST(root=\"data\", train=True, download=True,\n",
        "\ttransform=dataTransforms)\n",
        "testData = MNIST(root=\"data\", train=False, download=True,\n",
        "\ttransform=dataTransforms)\n",
        "data = torch.utils.data.ConcatDataset((trainData, testData))\n",
        "\n",
        "# initialize dataloader\n",
        "dataloader = DataLoader(data, shuffle=True,\n",
        "\tbatch_size=BATCH_SIZE)\n",
        "\n",
        "# calculate steps per epoch\n",
        "stepsPerEpoch = len(dataloader.dataset) // BATCH_SIZE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mg1UgqEIDHn"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hg5eusAOH2ds"
      },
      "outputs": [],
      "source": [
        "# build the generator, initialize it's weights, and flash it to the\n",
        "# current device\n",
        "print(\"[INFO] building generator...\")\n",
        "gen = Generator(inputDim=100, outputDim=512, outputChannels=1)\n",
        "gen.apply(weights_init)\n",
        "gen.to(DEVICE)\n",
        "\n",
        "# build the discriminator, initialize it's weights, and flash it to\n",
        "# the current device\n",
        "print(\"[INFO] building discriminator...\")\n",
        "disc = Discriminator(depth=1)\n",
        "disc.apply(weights_init)\n",
        "disc.to(DEVICE)\n",
        "\n",
        "# initialize optimizer for both geneator and discriminator\n",
        "genOpt = Adam(gen.parameters(), lr=0.0002, betas=(0.5, 0.999),\n",
        "\tweight_decay=0.0002 / NUM_EPOCHS)\n",
        "discOpt = Adam(disc.parameters(), lr=0.0002, betas=(0.5, 0.999),\n",
        "\tweight_decay=0.0002 / NUM_EPOCHS)\n",
        "\n",
        "# initialize BCELoss function\n",
        "criterion = BCELoss()\n",
        "\n",
        "# randomly generate some benchmark noise so we can consistently\n",
        "# visualize how the generative modeling is learning\n",
        "print(\"[INFO] starting training...\")\n",
        "benchmarkNoise = torch.randn(256, 100, 1, 1, device=DEVICE)\n",
        "\n",
        "# define real and fake label values\n",
        "realLabel = 1\n",
        "fakeLabel = 0\n",
        "\n",
        "# loop over the epochs\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "\t# show epoch information and compute the number of batches per\n",
        "\t# epoch\n",
        "\tprint(\"[INFO] starting epoch {} of {}...\".format(epoch + 1,\n",
        "\t\tNUM_EPOCHS))\n",
        "\n",
        "\t# initialize current epoch loss for generator and discriminator\n",
        "\tepochLossG = 0\n",
        "\tepochLossD = 0\n",
        "\n",
        "\tfor x in dataloader:\n",
        "\t\t# zero out the discriminator gradients\n",
        "\t\tdisc.zero_grad()\n",
        "\n",
        "\t\t# grab the images and send them to the device\n",
        "\t\timages = x[0]\n",
        "\t\timages = images.to(DEVICE)\n",
        "\n",
        "\t\t# get the batch size and create a labels tensor\n",
        "\t\tbs =  images.size(0)\n",
        "\t\tlabels = torch.full((bs,), realLabel, dtype=torch.float,\n",
        "\t\t\tdevice=DEVICE)\n",
        "\n",
        "\t\t# forward pass through discriminator\n",
        "\t\toutput = disc(images).view(-1)\n",
        "\n",
        "\t\t# calculate the loss on all-real batch\n",
        "\t\terrorReal = criterion(output, labels)\n",
        "\n",
        "\t\t# calculate gradients by performing a backward pass\n",
        "\t\terrorReal.backward()\n",
        "\n",
        "\t\t# randomly generate noise for the generator to predict on\n",
        "\t\tnoise = torch.randn(bs, 100, 1, 1, device=DEVICE)\n",
        "\n",
        "\t\t# generate a fake image batch using the generator\n",
        "\t\tfake = gen(noise)\n",
        "\t\tlabels.fill_(fakeLabel)\n",
        "\n",
        "\t\t# perform a forward pass through discriminator using fake\n",
        "\t\t# batch data\n",
        "\t\toutput = disc(fake.detach()).view(-1)\n",
        "\t\terrorFake = criterion(output, labels)\n",
        "\n",
        "\t\t# calculate gradients by performing a backward pass\n",
        "\t\terrorFake.backward()\n",
        "\n",
        "\t\t# compute the error for discriminator and update it\n",
        "\t\terrorD = errorReal + errorFake\n",
        "\t\tdiscOpt.step()\n",
        "\n",
        "\t\t# set all generator gradients to zero\n",
        "\t\tgen.zero_grad()\n",
        "\n",
        "\t\t# update the labels as fake labels are real for the generator\n",
        "\t\t# and perform a forward pass  of fake data batch through the\n",
        "\t\t# discriminator\n",
        "\t\tlabels.fill_(realLabel)\n",
        "\t\toutput = disc(fake).view(-1)\n",
        "\n",
        "\t\t# calculate generator's loss based on output from\n",
        "\t\t# discriminator and calculate gradients for generator\n",
        "\t\terrorG = criterion(output, labels)\n",
        "\t\terrorG.backward()\n",
        "\n",
        "\t\t# update the generator\n",
        "\t\tgenOpt.step()\n",
        "\n",
        "\t\t# add the current iteration loss of discriminator and\n",
        "\t\t# generator\n",
        "\t\tepochLossD += errorD\n",
        "\t\tepochLossG += errorG\n",
        "\n",
        "\t# display training information to disk\n",
        "\tprint(\"[INFO] Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(\n",
        "\t\tepochLossG / stepsPerEpoch, epochLossD / stepsPerEpoch))\n",
        "\n",
        "\t# check to see if we should visualize the output of the\n",
        "\t# generator model on our benchmark data\n",
        "\tif (epoch + 1) % 2 == 0:\n",
        "\t\t# set the generator in evaluation phase, make predictions on\n",
        "\t\t# the benchmark noise, scale it back to the range [0, 255],\n",
        "\t\t# and generate the montage\n",
        "\t\tgen.eval()\n",
        "\t\timages = gen(benchmarkNoise)\n",
        "\t\timages = images.detach().cpu().numpy().transpose((0, 2, 3, 1))\n",
        "\t\timages = ((images * 127.5) + 127.5).astype(\"uint8\")\n",
        "\t\timages = np.repeat(images, 3, axis=-1)\n",
        "\t\tvis = build_montages(images, (28, 28), (16, 16))[0]\n",
        "\n",
        "\t\t# build the output path and write the visualization to disk\n",
        "\t\tp = os.path.join(args[\"output\"], \"epoch_{}.png\".format(\n",
        "\t\t\tstr(epoch + 1).zfill(4)))\n",
        "\t\tcv2.imwrite(p, vis)\n",
        "\n",
        "\t\t# set the generator to training mode\n",
        "\t\tgen.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbuG-zVIKEoB"
      },
      "source": [
        "### Visualize the GIF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "epy7MV0FJ8pM"
      },
      "outputs": [],
      "source": [
        "Image(open(args[\"gif\"],\"rb\").read())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Sef8alx4cGYc"
      ],
      "name": "dcgan_pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
