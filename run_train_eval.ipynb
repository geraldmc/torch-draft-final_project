{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geraldmc/torch-draft-final_project/blob/main/load_deepweeds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DeepWeeds TRAIN & EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "import os.path\n",
        "import time\n",
        "from datetime import datetime\n",
        "import glob \n",
        "import shutil\n",
        "import copy\n",
        "import pathlib\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.data import RandomSampler, random_split\n",
        "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbxKpG6s9vK"
      },
      "source": [
        "### Download the code from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YZMmT0PtCog",
        "outputId": "7b990a66-048a-4e99-b36f-53e6b6171540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading file...\n",
            "--2022-03-29 22:06:09--  https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main [following]\n",
            "--2022-03-29 22:06:09--  https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 52.193.111.178\n",
            "Connecting to codeload.github.com (codeload.github.com)|52.193.111.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [ <=>                ] 526.76K  2.65MB/s    in 0.2s    \n",
            "\n",
            "2022-03-29 22:06:11 (2.65 MB/s) - ‘main.zip’ saved [539403]\n",
            "\n",
            "/content/torch-draft-final_project-main\n"
          ]
        }
      ],
      "source": [
        "if os.path.isfile(\"../main.zip\"):\n",
        "  print ('Have already downloaded the project file, continuing...')\n",
        "  print()\n",
        "else:\n",
        "  print ('Downloading file...')\n",
        "  ! wget https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
        "  ! unzip -qq main.zip\n",
        "  %cd torch-draft-final_project-main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "  import conf.params as params\n",
        "  from data import transforms as tsf\n",
        "  from data.test_loader import DeepWeeds_Test\n",
        "except ImportError:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVFrg7wPtJnj"
      },
      "source": [
        "### Download the dataset from Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTiLUTS_tUYp",
        "outputId": "bc228ab8-39b0-4f19-a12c-d8f1ee348aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "Downloading DeepWeeds images to /content/torch-draft-final_project-main/data/images.zip\n",
            "\n",
            "-rw------- 1 root root 491516047 Mar 29 22:07 /content/torch-draft-final_project-main/data/images.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "print()\n",
        "print(\"Downloading DeepWeeds images to \" + params.IMG_ZIP_FILE)\n",
        "!cp '{params.GD_ZIP_IMG}' '{params.IMG_ZIP_FILE}'\n",
        "print()\n",
        "!ls -lart {params.IMG_ZIP_FILE}\n",
        "\n",
        "print()\n",
        "print(\"Downloading GAN images to \" + params.GAN_ZIP_FILE)\n",
        "!cp '{params.GD_ZIP_GAN}' '{params.GAN_ZIP_FILE}'\n",
        "print()\n",
        "!ls -lart {params.GAN_ZIP_FILE}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Unzip the data files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"[INFO] Unzipping DeepWeeds images into \" +  params.IMG_DIRECTORY)\n",
        "\n",
        "with ZipFile(params.IMG_ZIP_FILE, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(params.IMG_DIRECTORY)\n",
        "\n",
        "img_list=os.listdir(params.IMG_DIRECTORY)\n",
        "print(len(img_list))\n",
        "\n",
        "print()\n",
        "print(\"[INFO] Unzipping GAN image dirs into \" + params.DATA_PATH)\n",
        "\n",
        "with ZipFile(params.GAN_ZIP_FILE, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(params.DATA_PATH)\n",
        "\n",
        "gan_dir_list=os.listdir(params.DATA_PATH+'/gans/train/0')\n",
        "print(len(gan_dir_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get imgaug installed and setup augmentations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/aleju/imgaug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia\n",
        "\n",
        "class ImgAugTransform:\n",
        "  def __init__(self):\n",
        "    self.aug = iaa.Sequential([\n",
        "        iaa.Resize((224, 224)),\n",
        "        iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Affine(rotate=(-20, 20), mode='symmetric'),\n",
        "        iaa.Sometimes(0.25,\n",
        "                      iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
        "                                 iaa.CoarseDropout(0.1, size_percent=0.5)])),\n",
        "        iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
        "    ])\n",
        "      \n",
        "  def __call__(self, img):\n",
        "    img = np.array(img)\n",
        "    return self.aug.augment_image(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Get the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOQZnKZBtlMa",
        "outputId": "9c511545-0a56-40d7-c028-0c28fc9f33c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "labels.csv\t  test_subset3.csv   train_subset2.csv\tval_subset1.csv\n",
            "test_subset0.csv  test_subset4.csv   train_subset3.csv\tval_subset2.csv\n",
            "test_subset1.csv  train_subset0.csv  train_subset4.csv\tval_subset3.csv\n",
            "test_subset2.csv  train_subset1.csv  val_subset0.csv\tval_subset4.csv\n"
          ]
        }
      ],
      "source": [
        "LABEL_PATH = os.path.join(params.DATA_PATH, 'labels')\n",
        "label_df = pd.read_csv(os.path.join(LABEL_PATH, 'labels.csv'))\n",
        "None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Steps For Train and Evaluate\n",
        "\n",
        "##### 0) Get files in order (mainly Colab-specific).\n",
        "\n",
        "    1) Instantiate new data loaders.\n",
        "    2) Init a new ResNet50 model.\n",
        "    3) Get/set the parameters to be optimized/updated.\n",
        "    4) Train the model. Save the best model.\n",
        "    5) Delete contents of the train/val directories.\n",
        "    6) REPEAT 1-6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Supporting functions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0) Functions for Colab - getting train, test, val files in place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_file_list():\n",
        "    files = []\n",
        "    for dirpath, dirnames, filenames in os.walk(params.IMAGE_PATH):\n",
        "        for file in filenames:\n",
        "            files.append(file)\n",
        "    return files\n",
        "\n",
        "def copy_files(df, files, filepath):\n",
        "  labels = dict(zip(df.Filename, df.Label)) \n",
        "  for f in files:\n",
        "      try:\n",
        "          src = os.path.join(params.IMG_DIRECTORY, f)\n",
        "          dst = os.path.join(filepath, str(labels[f]), f)\n",
        "          shutil.copyfile(src, dst)\n",
        "      except KeyError:\n",
        "          pass\n",
        "\n",
        "def delete_train_val_files(path):\n",
        "  for sub_dir in sorted(os.listdir(path)):\n",
        "    for file_name in os.listdir(os.path.join(path, sub_dir)):\n",
        "      file = os.path.join(path, sub_dir, file_name)\n",
        "      if os.path.isfile(file):\n",
        "        os.remove(file)\n",
        "\n",
        "def copy_test_files(df, filepath):\n",
        "  for f in df.Filename:\n",
        "      try:\n",
        "          src = os.path.join(params.IMG_DIRECTORY, f)\n",
        "          dst = os.path.join(filepath, f)\n",
        "          shutil.copyfile(src, dst)\n",
        "      except KeyError:\n",
        "          pass\n",
        "\n",
        "def delete_test_files(path):\n",
        "  for file_name in os.listdir(params.IMG_TEST_PATH):\n",
        "    file = os.path.join(path, file_name)\n",
        "    if os.path.isfile(file):\n",
        "      os.remove(file)\n",
        "\n",
        "def get_dataloader_counts(dl):\n",
        "  from collections import Counter\n",
        "  try:\n",
        "    train_dict = dict(Counter(\n",
        "        dl['train'].dataset.datasets[0].targets))\n",
        "    val_dict = dict(Counter(\n",
        "        dl['val'].dataset.datasets[0].targets))\n",
        "  except AttributeError:\n",
        "    #print('error')\n",
        "    train_dict = dict(Counter(\n",
        "        dl['train'].dataset.targets))\n",
        "    val_dict = dict(Counter(\n",
        "        dl['val'].dataset.targets))\n",
        " \n",
        "  return train_dict, val_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### 1a) Prepare single data loader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_single_dataloader(batch_size):\n",
        "    '''FIXME\n",
        "    '''\n",
        "    train_data_single = ImageFolder(\n",
        "        root=params.IMG_TRAIN_PATH, \n",
        "        transform=tsf.base_transform)\n",
        "    train_loader_single = DataLoader(train_data_single, \n",
        "        batch_size=batch_size, shuffle=True, \n",
        "        num_workers=2,\n",
        "        pin_memory=torch.cuda.is_available())\n",
        "\n",
        "    val_data_single = ImageFolder(\n",
        "        root=params.IMG_VAL_PATH, \n",
        "        transform=tsf.base_transform)\n",
        "    val_loader_single = DataLoader(val_data_single, \n",
        "        batch_size=batch_size, shuffle=False, \n",
        "        num_workers=2,\n",
        "        pin_memory=torch.cuda.is_available())\n",
        "\n",
        "    dataloaders_gan = {}\n",
        "    dataloaders_gan['train'] = train_loader_single\n",
        "    dataloaders_gan['val'] = val_loader_single\n",
        "\n",
        "    return dataloaders_gan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### 1b) Prepare DeepWeeds augmented data loader (version 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_DW_dataloaders1(batch_size):\n",
        "     \n",
        "     transforms = ImgAugTransform() # imgaug no workie.\n",
        "     \n",
        "# Each training dataset contains 8382 x 5 images.\n",
        "# Shuffle is True for train, False for val.\n",
        "# See https://stackoverflow.com/questions/60614673/accuracy-reduced-when-shuffle-set-to-true-in-keras-fit-generator\n",
        "\n",
        "\n",
        "     train_loader_aug = DataLoader(\n",
        "     ConcatDataset([ImageFolder(\n",
        "               params.IMG_TRAIN_PATH, \n",
        "               transform=tsf.data_transforms['default']),\n",
        "          ImageFolder(\n",
        "               params.IMG_TRAIN_PATH,\n",
        "               transform=tsf.data_transforms['default']),\n",
        "          ImageFolder(\n",
        "               params.IMG_TRAIN_PATH,\n",
        "               transform=tsf.data_transforms['default']),\n",
        "          ImageFolder(\n",
        "               params.IMG_TRAIN_PATH,\n",
        "               transform=tsf.data_transforms['grayscale']),\n",
        "          ImageFolder(\n",
        "               params.IMG_TRAIN_PATH,\n",
        "               transform=tsf.data_transforms['jitter_hue'])]), \n",
        "               batch_size=batch_size, \n",
        "               shuffle=True, num_workers=2, \n",
        "               pin_memory=torch.cuda.is_available())\n",
        "\n",
        "     # Each validation dataset contains 3251 x 5 images.\n",
        "\n",
        "     val_loader_aug = DataLoader(\n",
        "     ConcatDataset([ImageFolder(\n",
        "               params.IMG_VAL_PATH, \n",
        "               transform=tsf.data_transforms['default']),\n",
        "          ImageFolder(\n",
        "               params.IMG_VAL_PATH,\n",
        "               transform=tsf.data_transforms['default']),\n",
        "          ImageFolder(\n",
        "               params.IMG_VAL_PATH,\n",
        "               transform=tsf.data_transforms['default']),\n",
        "          ImageFolder(\n",
        "               params.IMG_VAL_PATH,\n",
        "               transform=tsf.data_transforms['grayscale']),\n",
        "          ImageFolder(\n",
        "               params.IMG_VAL_PATH,\n",
        "               transform=tsf.data_transforms['jitter_hue'])]), \n",
        "               batch_size=batch_size, \n",
        "               shuffle=False, num_workers=2, # shuffle is False for val!\n",
        "               pin_memory=torch.cuda.is_available())\n",
        "\n",
        "     dataloaders_aug = {}\n",
        "     dataloaders_aug['train'] = train_loader_aug\n",
        "     dataloaders_aug['val'] = val_loader_aug\n",
        "\n",
        "     #print(\"Cumulative length of train:\", dataloaders_aug['train'].dataset.cumulative_sizes)\n",
        "     #print(\"Cumulative length of val:\", dataloaders_aug['val'].dataset.cumulative_sizes)\n",
        "\n",
        "     return dataloaders_aug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### 1c) Prepare DeepWeeds augmented data loader (version 2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_DW_dataloaders2(batch_size):\n",
        "     \n",
        "     transforms = ImgAugTransform() # imgaug no workie.\n",
        "     \n",
        "# Each training dataset contains 8382 x 5 images.\n",
        "# Shuffle is True for train, False for val.\n",
        "# See https://stackoverflow.com/questions/60614673/accuracy-reduced-when-shuffle-set-to-true-in-keras-fit-generator\n",
        "\n",
        "\n",
        "     train_loader_aug = DataLoader(\n",
        "     ConcatDataset([ImageFolder(\n",
        "               params.IMG_TRAIN_PATH, \n",
        "               transform=tsf.data_transforms['hvflip']),\n",
        "          ImageFolder(\n",
        "               params.IMG_TRAIN_PATH,\n",
        "               transform=tsf.data_transforms['crop']),\n",
        "          ImageFolder(\n",
        "               params.IMG_TRAIN_PATH,\n",
        "               transform=tsf.data_transforms['translate']),\n",
        "          ImageFolder(\n",
        "               params.IMG_TRAIN_PATH,\n",
        "               transform=tsf.data_transforms['grayscale']),\n",
        "          ImageFolder(\n",
        "               params.IMG_TRAIN_PATH,\n",
        "               transform=tsf.data_transforms['jitter_hue'])]), \n",
        "               batch_size=batch_size, \n",
        "               shuffle=True, num_workers=2, \n",
        "               pin_memory=torch.cuda.is_available())\n",
        "\n",
        "     # Each validation dataset contains 3251 x 5 images.\n",
        "\n",
        "     val_loader_aug = DataLoader(\n",
        "     ConcatDataset([ImageFolder(\n",
        "               params.IMG_VAL_PATH, \n",
        "               transform=tsf.data_transforms['hvflip']),\n",
        "          ImageFolder(\n",
        "               params.IMG_VAL_PATH,\n",
        "               transform=tsf.data_transforms['crop']),\n",
        "          ImageFolder(\n",
        "               params.IMG_VAL_PATH,\n",
        "               transform=tsf.data_transforms['translate']),\n",
        "          ImageFolder(\n",
        "               params.IMG_VAL_PATH,\n",
        "               transform=tsf.data_transforms['grayscale']),\n",
        "          ImageFolder(\n",
        "               params.IMG_VAL_PATH,\n",
        "               transform=tsf.data_transforms['jitter_hue'])]), \n",
        "               batch_size=batch_size, \n",
        "               shuffle=False, num_workers=2, # shuffle is False for val!\n",
        "               pin_memory=torch.cuda.is_available())\n",
        "\n",
        "     dataloaders_aug = {}\n",
        "     dataloaders_aug['train'] = train_loader_aug\n",
        "     dataloaders_aug['val'] = val_loader_aug\n",
        "\n",
        "     #print(\"Cumulative length of train:\", dataloaders_aug['train'].dataset.cumulative_sizes)\n",
        "     #print(\"Cumulative length of val:\", dataloaders_aug['val'].dataset.cumulative_sizes)\n",
        "\n",
        "     return dataloaders_aug"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " ### 1b) Prepare COMBINED data loaders (DeepWeed images, with GANs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_comb_dataloaders(transform_method='original'):\n",
        "    '''FIXME\n",
        "    '''\n",
        "    \n",
        "    GAN_TRAIN_PATH = os.path.join(params.DATA_PATH, 'gans/train')\n",
        "\n",
        "    image_list = []\n",
        "\n",
        "    if transform_method == 'original':\n",
        "        image_list.append(ImageFolder(\n",
        "            root=GAN_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['original']))\n",
        "        image_list.append(ImageFolder(\n",
        "            root=params.IMG_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['original']))\n",
        "\n",
        "    elif transform_method == 'random':\n",
        "        image_list.append(ImageFolder(\n",
        "            root=GAN_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['random_augment']))\n",
        "        image_list.append(ImageFolder(\n",
        "            root=params.IMG_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['random_augment']))\n",
        "\n",
        "    elif transform_method == 'auto':\n",
        "        image_list.append(ImageFolder(\n",
        "            root=GAN_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['ImageNet_autoaug']))\n",
        "        image_list.append(ImageFolder(\n",
        "            root=params.IMG_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['ImageNet_autoaug']))\n",
        "\n",
        "    elif transform_method == 'grayscale':\n",
        "        image_list.append(ImageFolder(\n",
        "            root=GAN_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['grayscale']))\n",
        "        image_list.append(ImageFolder(\n",
        "            root=params.IMG_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['grayscale']))\n",
        "\n",
        "    elif transform_method == 'translate':\n",
        "        image_list.append(ImageFolder(\n",
        "            root=GAN_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['translate']))\n",
        "        image_list.append(ImageFolder(\n",
        "            root=params.IMG_TRAIN_PATH, \n",
        "            transform=tsf.data_transforms['translate']))\n",
        "    else:\n",
        "        pass #FIXME, handle this somehow\n",
        "\n",
        "\n",
        "    image_datasets = ConcatDataset(image_list)\n",
        "\n",
        "    img_sets = dict()\n",
        "    img_sets['train'], img_sets['val'] = random_split(image_datasets, \n",
        "                                        (round(0.8*len(image_datasets)), \n",
        "                                        round(0.2*len(image_datasets))))\n",
        "\n",
        "    combined_train_loader = DataLoader(img_sets['train'], \n",
        "                                    batch_size=32, shuffle=True, \n",
        "                                    num_workers=2)\n",
        "\n",
        "    combined_val_loader = DataLoader(img_sets['val'], \n",
        "                                    batch_size=32, shuffle=True, \n",
        "                                    num_workers=2)\n",
        "    dataloaders = {}\n",
        "    dataloaders['train'] = combined_train_loader\n",
        "    dataloaders['val'] = combined_val_loader\n",
        "\n",
        "    return dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) Init a new ResNet50 model.\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    '''FIXME\n",
        "    '''\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract):\n",
        "    '''FIXME\n",
        "    '''\n",
        "     # Init a new ResNet50 model (called below)\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "    if model_name == \"resnet50\":\n",
        "        \"\"\" Resnet50\n",
        "        \"\"\"\n",
        "        model_ft = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "def init_model():\n",
        "    '''FIXME\n",
        "    '''\n",
        "    model, input_size = initialize_model('resnet50', params.NUM_CLASSES, \n",
        "                                            feature_extract=True)\n",
        "    if torch.cuda.is_available():\n",
        "        model.to('cuda') #IMPORTANT!\n",
        "    \n",
        "    return model, input_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#4) Get/set the parameters to be optimized/updated for each k-fold.\n",
        "\n",
        "def get_parameters(model, features):\n",
        "    '''  Only parameters that we've just initialized, i.e. the parameters with \n",
        "         requires_grad is True, are updated. (i.e. the last fc layer).\n",
        "    '''\n",
        "\n",
        "    params_to_update = model.parameters()\n",
        "\n",
        "    print(\"[INFO] Params to learn:\")\n",
        "    if features:\n",
        "        params_to_update = []\n",
        "        for name,param in model.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                params_to_update.append(param)\n",
        "                print(\"\\t\",name)\n",
        "    else:\n",
        "        for name,param in model.named_parameters():\n",
        "            if param.requires_grad == True:\n",
        "                print(\"\\t\",name)\n",
        "    print()\n",
        "\n",
        "    # Observe that all parameters are optimized\n",
        "    # optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
        "    opt = optim.Adam(params_to_update, lr=1e-3)\n",
        "    sch = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        opt, patience=16, factor=0.5, min_lr=0.00003125)\n",
        "\n",
        "    return opt, sch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "    .                       o8o\n",
        "  .o8                       `\"'\n",
        ".o888oo oooo d8b  .oooo.   oooo  ooo. .oo.\n",
        "  888   `888\"\"8P `P  )88b  `888  `888P\"Y88b\n",
        "  888    888      .oP\"888   888   888   888\n",
        "  888 .  888     d8(  888   888   888   888\n",
        "  \"888\" d888b    `Y888\"\"8o o888o o888o o888o\n",
        "'''\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs):\n",
        "    '''FIXME\n",
        "    '''\n",
        "    since = time.time()\n",
        "\n",
        "    # lists to store per-epoch loss and accuracy values\n",
        "    val_acc_history, val_loss_history = [], []\n",
        "    train_acc_history, train_loss_history = [], []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('[INFO] Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 16)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(params.DEVICE)\n",
        "                labels = labels.to(params.DEVICE)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "                    #else: # val mode\n",
        "                        #scheduler.step(loss) # optimizer to scheduler for eval\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "            print('\\t{} loss: {:.4f} acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "                val_loss_history.append(epoch_loss)\n",
        "            elif phase == 'train':\n",
        "                train_acc_history.append(epoch_acc)\n",
        "                train_loss_history.append(epoch_loss)\n",
        "        print()\n",
        "    time_elapsed = time.time() - since\n",
        "    print('[INFO] Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('[INFO] Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, val_loss_history, train_acc_history, train_loss_history, best_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, dataloaders, optimizer, scheduler, epochs):\n",
        "  '''FIXME\n",
        "  '''\n",
        "  criterion = nn.CrossEntropyLoss() # (i.e. binary_crossentropy)\n",
        "  model, va, vl, ta, tl, best_acc = train_model(model, dataloaders, criterion, \n",
        "                                                optimizer, scheduler, num_epochs=epochs)\n",
        "  return model, va, vl, ta, tl, best_acc\n",
        "\n",
        "def save_model(m, name):\n",
        "  '''FIXME\n",
        "  '''\n",
        "  # provide a timestamp\n",
        "  timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S')\n",
        "  saved_name = os.path.join(params.OUTPUT_PATH, str(timestamp) + name + '_model.pth')\n",
        "  torch.save(m.state_dict(), saved_name)\n",
        "  return saved_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_plots(va, vl, ta, tl):\n",
        "    '''FIXME\n",
        "    '''\n",
        "    # Convert tensor objects to lists\n",
        "    val_acc_record = [va[x].item() for x in range(len(va))]\n",
        "    val_loss_record = [vl[x] for x in range(len(vl))]\n",
        "    train_acc_record = [ta[x].item() for x in range(len(ta))]\n",
        "    train_loss_record = [tl[x] for x in range(len(tl))]\n",
        "    \n",
        "    # Accuracy plots\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(train_acc_record, color='green', label='train acc')\n",
        "    plt.plot(val_acc_record, color='blue', label='val acc')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    #plt.savefig(f\"outputs/{acc_plot_name}.png\")\n",
        "    #plt.show()\n",
        "\n",
        "    # Loss plots\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(train_loss_record, color='orange', label='train loss')\n",
        "    plt.plot(val_loss_record, color='red', label='val loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    #plt.savefig(f\"../outputs/{loss_plot_name}.png\")\n",
        "    #plt.show()\n",
        "\n",
        "    # Train acc versus loss\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(train_acc_record, color='blue', label='train acc')\n",
        "    plt.plot(train_loss_record, color='green', label='train loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy/Loss')\n",
        "    plt.legend()\n",
        "    #plt.savefig(f\"../outputs/{acc_plot_name}.png\")\n",
        "    #plt.show()\n",
        "\n",
        "    # Val acc versus loss\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.plot(val_acc_record, color='red', label='val acc')\n",
        "    plt.plot(val_loss_record, color='orange', label='val loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy/Loss')\n",
        "    plt.legend()\n",
        "    #plt.savefig(f\"../outputs/{acc_plot_name}.png\")\n",
        "    #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_train_kfold(loader, batch):\n",
        "  '''FIXME\n",
        "  '''\n",
        "  files = get_file_list()\n",
        "  best_epoch_accs = []\n",
        "\n",
        "  # K-fold cross validation, saving outputs for each fold.\n",
        "  for idx in range(params.FOLDS):\n",
        "      \n",
        "    timestamp = datetime.fromtimestamp(time.time()).strftime('%Y%m%d-%H%M%S')\n",
        "    print()\n",
        "    print('[INFO] Fold {}/{} - {}'.format(idx + 1, params.FOLDS, timestamp))\n",
        "    output_directory = \"{}/{}/\".format(params.OUTPUT_PATH, timestamp)\n",
        "    if not os.path.exists(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "\n",
        "    train_label_file = \"{}/train_subset{}.csv\".format(LABEL_PATH, idx)\n",
        "    val_label_file = \"{}/val_subset{}.csv\".format(LABEL_PATH, idx)\n",
        "\n",
        "    train_df = pd.read_csv(train_label_file)\n",
        "    val_df = pd.read_csv(val_label_file)\n",
        "\n",
        "    copy_files(train_df, files, params.IMG_TRAIN_PATH)\n",
        "    copy_files(val_df, files, params.IMG_VAL_PATH)\n",
        "\n",
        "    if loader == '_no_aug':\n",
        "      deepweeds = get_single_dataloader(batch)\n",
        "    elif loader == '_aug1':\n",
        "      deepweeds = get_DW_dataloaders1(batch)\n",
        "    elif loader == '_aug2':\n",
        "      deepweeds = get_DW_dataloaders2(batch)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "    # Stats for the datasets. \n",
        "    train_dict, val_dict = {},{}\n",
        "    train_dict, val_dict = get_dataloader_counts(deepweeds)\n",
        "\n",
        "    print()\n",
        "    print('[{}/{}] Deepweeds Train Class Distribution: {}'.format(idx + 1, \n",
        "                                            params.FOLDS, train_dict))\n",
        "\n",
        "    print('[{}/{}] Deepweeds Val Class Distribution: {}'.format(idx + 1, \n",
        "                                            params.FOLDS, val_dict))\n",
        "    print()\n",
        "    torch_resnet50, input_size = init_model()\n",
        "    optimizer, scheduler = get_parameters(torch_resnet50, features=True)\n",
        "    best_model_wts, va, vl, ta, tl, best_acc = train(torch_resnet50, deepweeds, \n",
        "                                            optimizer, scheduler, 2)\n",
        "\n",
        "    saved_name = save_model(best_model_wts, loader)\n",
        "    best_epoch_accs.append(best_acc) \n",
        "    make_plots(va, vl, ta, tl)\n",
        "\n",
        "    # Assure that files are reset -----------------------------------\n",
        "    assert len(os.listdir(params.IMG_TRAIN_PATH + '/0')) != 0\n",
        "    delete_train_val_files(params.IMG_TRAIN_PATH)\n",
        "    assert len(os.listdir(params.IMG_TRAIN_PATH + '/0')) == 0\n",
        "    delete_train_val_files(params.IMG_VAL_PATH)\n",
        "    assert len(os.listdir(params.IMG_VAL_PATH + '/0')) == 0\n",
        "\n",
        "  return best_epoch_accs, saved_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------ RUN TRAIN/EVAL ------------------------------------\n",
        "batch = 32\n",
        "best_fold_accs, saved_name = run_train_kfold('_no_aug', batch)\n",
        "# ----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def copy_pth_to_gdrive(path_to_model):\n",
        "  '''FIXME\n",
        "  '''\n",
        "  shutil.copy(path_to_model, params.GD_WRITE_DIR)\n",
        "  \n",
        "copy_pth_to_gdrive(saved_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Steps For Test\n",
        "\n",
        "##### 0) Get files in order (mainly Colab-specific).\n",
        "\n",
        "    1) Copy files to single directory (not using ImageFolder).\n",
        "    2) Instantiate data loaders.\n",
        "    3) Load the trained ResNet50 model.\n",
        "    4) Test the model. Save results.\n",
        "    5) Delete contents of the test directory.\n",
        "    7) REPEAT 1-5."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def return_last_pth():\n",
        "  filename = max([f for f in pathlib.Path(params.OUTPUT_PATH).glob('*_model.pth')],\n",
        "                key=os.path.getctime)\n",
        "  return filename\n",
        "\n",
        "def print_states(m):\n",
        "    # Print the model's state_dict\n",
        "    print(\"Model's state_dict:\")\n",
        "    for param_tensor in m.state_dict():\n",
        "        print(param_tensor, \"\\t\", m.state_dict()[param_tensor].size())\n",
        "\n",
        "def load_model(name):\n",
        "    '''FIXME\n",
        "    '''\n",
        "    model, input_size = init_model()\n",
        "    model.load_state_dict(torch.load(name))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "'''\n",
        "    .                          .\n",
        "  .o8                        .o8\n",
        "888oo  .ooooo.   .oooo.o .o888oo\n",
        "  888   d88' `88b d88(  \"8   888\n",
        "  888   888ooo888 `\"Y88b.    888\n",
        "  888 . 888    .o o.  )88b   888 .\n",
        "  \"888\" `Y8bod8P' 8\"\"888P'   \"888\"\n",
        "'''\n",
        "\n",
        "def test(test_loader, model):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    targets, preds = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            if torch.cuda.is_available():\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "            output = model(data)\n",
        "            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "            targets += list(target.cpu().numpy())\n",
        "            preds += list(pred.cpu().numpy())\n",
        "\n",
        "    test_acc = 100. * correct / len(test_loader.dataset)\n",
        "    confusion_mtx = sm.confusion_matrix(targets, preds)\n",
        "    return test_acc, confusion_mtx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_test_kfold(model):\n",
        "\n",
        "  for idx in range(params.FOLDS):\n",
        "    test_label_file = \"{}/test_subset{}.csv\".format(LABEL_PATH, idx)\n",
        "    test_df = pd.read_csv(test_label_file)\n",
        "    copy_test_files(test_df, params.IMG_TEST_PATH)\n",
        "\n",
        "    test_dataset = DeepWeeds_Test(test_label_file)\n",
        "    print(len(test_dataset))\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, \n",
        "        batch_size=params.BATCH_SIZE, shuffle=False,\n",
        "        pin_memory=torch.cuda.is_available(), \n",
        "        num_workers=2)\n",
        "\n",
        "    # --- Get metrics for each fold.\n",
        "    test_acc, confusion_mtx = test(test_loader, model)\n",
        "    # ---\n",
        "\n",
        "    delete_test_files(params.IMG_TEST_PATH)\n",
        "    cnt = len([name for name in os.listdir(params.IMG_TEST_PATH) \\\n",
        "              if os.path.isfile(os.path.join(params.IMG_TEST_PATH, name))])\n",
        "    #assert cnt == 0\n",
        "    print(cnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ------------ RUN TEST ------------------------------------------\n",
        "name = return_last_pth()\n",
        "model = load_model(name)\n",
        "\n",
        "run_test_kfold(model)\n",
        "# ----------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_label_file = \"{}/test_subset{}.csv\".format(LABEL_PATH, 0)\n",
        "\n",
        "test_dataset = DeepWeeds_Test(test_label_file)\n",
        "print(len(test_dataset))\n",
        "\n",
        "test_loader = DataLoader(test_dataset, \n",
        "    batch_size=params.BATCH_SIZE, shuffle=False,\n",
        "    pin_memory=torch.cuda.is_available(), \n",
        "    num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ALL FOLLOWING MAY GO AWAY....."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# THIS IS NOT USED IN THE K-FOLDS CODE BELOW. IT CAN BE USED SEPARATELY. \n",
        "\n",
        "# 2) Instantiate data loaders for one k-fold.\n",
        "\n",
        "print(\"[INFO] Initializing Datasets and Dataloaders...\")\n",
        "\n",
        "# Create train and val datasets\n",
        "image_datasets = {x: ImageFolder(os.path.join(params.DATA_PATH, x), \n",
        "                                 tsf.paired_transforms[x]) \n",
        "                                  for x in ['train', 'val']}\n",
        "# Create train and val dataloaders\n",
        "dataloaders_nogan = {x: DataLoader(image_datasets[x], \n",
        "                                  batch_size=params.BATCH_SIZE, \n",
        "                                  shuffle=True, num_workers=2) \n",
        "                                  for x in ['train', 'val']}\n",
        "                                  \n",
        "GAN_TRAIN_PATH = os.path.join(params.DATA_PATH, 'gans/train')\n",
        "GAN_VAL_PATH = os.path.join(params.DATA_PATH, 'gans/val')\n",
        "\n",
        "train_data_gan = ImageFolder(\n",
        "    root=GAN_TRAIN_PATH, \n",
        "    transform=tsf.base_transform)\n",
        "train_loader_gan = DataLoader(train_data_gan, \n",
        "    batch_size=32, shuffle=True, \n",
        "    num_workers=2)\n",
        "\n",
        "val_data_gan = ImageFolder(\n",
        "    root=GAN_VAL_PATH, \n",
        "    transform=tsf.base_transform)\n",
        "val_loader_gan = DataLoader(val_data_gan, \n",
        "    batch_size=32, shuffle=True, \n",
        "    num_workers=2)\n",
        "\n",
        "dataloaders_gan = {}\n",
        "dataloaders_gan['train'] = train_loader_gan\n",
        "dataloaders_gan['val'] = val_loader_gan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_random_GANs():\n",
        "\n",
        "  GAN_TRAIN_PATH = os.path.join(params.DATA_PATH, 'gans/train')\n",
        "  GAN_VAL_PATH = os.path.join(params.DATA_PATH, 'gans/val')\n",
        "\n",
        "  for idx in range(0, params.NUM_CLASSES):\n",
        "    train_random_25 = {}\n",
        "    train_random_15 = {}\n",
        "    train_random_10 = {}\n",
        "\n",
        "    val_random_25 = {}\n",
        "    val_random_15 = {}\n",
        "    val_random_10 = {}\n",
        "\n",
        "    target = os.path.join(GAN_TRAIN_PATH, str(idx))\n",
        "    files = [f for f in os.listdir(target) if \\\n",
        "            os.path.isfile(os.path.join(target, f))]\n",
        "    train_random_25[str(idx)] = list(np.random.choice(files, 158)) # %25\n",
        "    train_random_15[str(idx)] = list(np.random.choice(files, 95)) # %15\n",
        "    train_random_10[str(idx)] = list(np.random.choice(files, 63)) # %10\n",
        "\n",
        "\n",
        "    target = os.path.join(GAN_VAL_PATH, str(idx))\n",
        "    files = [f for f in os.listdir(target) if \\\n",
        "            os.path.isfile(os.path.join(target, f))]\n",
        "    val_random_25[str(idx)] = list(np.random.choice(files, 158)) # %25\n",
        "    val_random_15[str(idx)] = list(np.random.choice(files, 95)) # %15\n",
        "    val_random_10[str(idx)] = list(np.random.choice(files, 63)) # %10\n",
        "    #random_files = np.random.choice(files, int(len(files)*.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx2class = {v: k for k, v in train_data_gan.class_to_idx.items()}\n",
        "\n",
        "def get_class_distribution(dataset_obj):\n",
        "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
        "    \n",
        "    for element in dataset_obj:\n",
        "        y_lbl = element[1]\n",
        "        y_lbl = idx2class[y_lbl]\n",
        "        count_dict[y_lbl] += 1\n",
        "            \n",
        "    return count_dict\n",
        "print(\"Distribution of classes: \\n\", get_class_distribution(train_data_gan))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_class_distribution_loaders(dataloader_obj, dataset_obj):\n",
        "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
        "    \n",
        "    for _, j in dataloader_obj:\n",
        "        y_idx = j.item()\n",
        "        y_lbl = idx2class[y_idx]\n",
        "        count_dict[str(y_lbl)] += 1\n",
        "            \n",
        "    return count_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "''' GUTTER ------ \n",
        "'''"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNakgWdfr0oHr8HQcRFOsFM",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "load_deepweeds.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
