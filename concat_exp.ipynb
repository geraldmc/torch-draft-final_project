{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geraldmc/torch-draft-final_project/blob/main/concat_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vEQjq5zCM3mT"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import time\n",
        "from datetime import datetime\n",
        "import glob \n",
        "import shutil\n",
        "import copy\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.data import RandomSampler, random_split\n",
        "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Look at cells 8, 9, and 10. "
      ],
      "metadata": {
        "id": "xq9Tc6cCQwii"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbxKpG6s9vK"
      },
      "source": [
        "### Download the code from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YZMmT0PtCog",
        "outputId": "bd6b3e6f-1e73-42e3-cf69-1a602cb01c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file...\n",
            "--2022-04-23 15:10:26--  https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main [following]\n",
            "--2022-04-23 15:10:26--  https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 52.193.111.178\n",
            "Connecting to codeload.github.com (codeload.github.com)|52.193.111.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [  <=>               ]   2.60M  8.79MB/s    in 0.3s    \n",
            "\n",
            "2022-04-23 15:10:27 (8.79 MB/s) - ‘main.zip’ saved [2722461]\n",
            "\n",
            "/content/torch-draft-final_project-main\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.path.isfile(\"../main.zip\"):\n",
        "  print ('Have already downloaded the project file, continuing...')\n",
        "  print()\n",
        "else:\n",
        "  print ('Downloading file...')\n",
        "  ! wget https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
        "  ! unzip -qq main.zip\n",
        "  %cd torch-draft-final_project-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "80iS3idAM3mU"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import conf.params as params\n",
        "  from data import transforms as tsf\n",
        "except ImportError:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "print()\n",
        "print(\"Downloading DeepWeeds images to \" + params.IMG_ZIP_FILE)\n",
        "!cp '{params.GD_ZIP_IMG}' '{params.IMG_ZIP_FILE}'\n",
        "print()\n",
        "!ls -lart {params.IMG_ZIP_FILE}\n",
        "\n",
        "print()\n",
        "print(\"Downloading GAN images to \" + params.GAN_ZIP_FILE)\n",
        "!cp '{params.GD_ZIP_GAN}' '{params.GAN_ZIP_FILE}'\n",
        "print()\n",
        "!ls -lart {params.GAN_ZIP_FILE}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtEnDyb9NKSY",
        "outputId": "18418b01-dbf8-4982-826f-ead41b301ac8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "\n",
            "Downloading DeepWeeds images to data/images.zip\n",
            "\n",
            "-rw------- 1 root root 491516047 Apr 23 15:10 data/images.zip\n",
            "\n",
            "Downloading GAN images to data/gans.zip\n",
            "\n",
            "-rw------- 1 root root 53284865 Apr 23 15:10 data/gans.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Unzipping DeepWeeds images into \" +  params.IMG_DIRECTORY)\n",
        "\n",
        "with ZipFile(params.IMG_ZIP_FILE, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(params.IMG_DIRECTORY)\n",
        "\n",
        "img_list=os.listdir(params.IMG_DIRECTORY)\n",
        "print(len(img_list))\n",
        "\n",
        "print()\n",
        "print(\"[INFO] Unzipping GAN image dirs into \" + params.DATA_PATH)\n",
        "\n",
        "with ZipFile(params.GAN_ZIP_FILE, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(params.DATA_PATH)\n",
        "\n",
        "gan_dir_list=os.listdir(params.DATA_PATH+'/gans/train/0')\n",
        "print(len(gan_dir_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifx_iZznNZyi",
        "outputId": "0f11f5cc-63ef-428a-837a-672ea12edb51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Unzipping DeepWeeds images into data/images\n",
            "17510\n",
            "\n",
            "[INFO] Unzipping GAN image dirs into data\n",
            "750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGBEIPMM3mU"
      },
      "source": [
        "### 1) Combine train, test, val files, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k5PGmGFeM3mU"
      },
      "outputs": [],
      "source": [
        "import glob \n",
        "\n",
        "joined_val = os.path.join(\"data/\", \"labels/\", \"val*.csv\")\n",
        "joined_train = os.path.join(\"data/\", \"labels/\", \"train*.csv\")\n",
        "joined_test = os.path.join(\"data/\", \"labels/\", \"test*.csv\")\n",
        "\n",
        "val_files = glob.glob(joined_val)\n",
        "train_files = glob.glob(joined_train)\n",
        "test_files = glob.glob(joined_test)\n",
        "\n",
        "train_df = pd.concat(map(pd.read_csv, train_files), ignore_index=True)\n",
        "val_df = pd.concat(map(pd.read_csv, val_files), ignore_index=True)\n",
        "test_df = pd.concat(map(pd.read_csv, test_files), ignore_index=True)\n",
        "\n",
        "# In the paper, each fold contains 10,505 samples from the total\n",
        "def sample_data(train_sample_no, val_sample_no, test_sample_no): \n",
        "    train = train_df.sample(n=train_sample_no)\n",
        "    val = val_df.sample(n=val_sample_no)\n",
        "    test = test_df.sample(n=test_sample_no)\n",
        "    return train, val, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SgMdUhWM3mV"
      },
      "source": [
        "### 2) Copy files to their respective directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "82K5oW7oM3mV"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "files = []\n",
        "for dirpath, dirnames, filenames in os.walk(params.IMAGE_PATH):\n",
        "    for file in filenames:\n",
        "        files.append(file)\n",
        "\n",
        "def copy_files(df, filepath):\n",
        "\n",
        "  labels = dict(zip(df.Filename, df.Label)) \n",
        "  for f in files:\n",
        "      try:\n",
        "          src = os.path.join(params.IMG_DIRECTORY, f)\n",
        "          dst = os.path.join(filepath, str(labels[f]), f)\n",
        "          shutil.copyfile(src, dst)\n",
        "      except KeyError:\n",
        "          pass\n",
        "\n",
        "# sample number same as paper.\n",
        "sample_train_df = train_df.sample(n=10505)\n",
        "sample_val_df = val_df.sample(n=3502)\n",
        "sample_test_df = test_df.sample(n=3502) \n",
        "\n",
        "copy_files(sample_train_df, params.IMG_TRAIN_PATH)\n",
        "copy_files(sample_val_df, params.IMG_VAL_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNrM2EqkM3mV"
      },
      "source": [
        "### 3) Instantiate the data loaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo4BHFQgM3mV",
        "outputId": "08e5ae22-067e-4817-f1c9-50ea1365fd7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative length of the train dataloaders: [8394, 16788, 25182, 33576, 41970]\n",
            "Cumulative length of the val dataloaders: [3246, 6492, 9738, 12984, 16230]\n"
          ]
        }
      ],
      "source": [
        "from data import transforms as tsf\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Each training dataset contains 8382 x 5 images.\n",
        "\n",
        "train_loader = DataLoader(\n",
        " ConcatDataset([ImageFolder(\n",
        "          params.IMG_TRAIN_PATH, \n",
        "          transform=tsf.base_transform),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=tsf.data_translate),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=tsf.data_grayscale),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=tsf.data_rotate),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=tsf.data_jitter_hue)]), \n",
        "          batch_size=1, \n",
        "          shuffle=True, num_workers=2, \n",
        "          pin_memory=torch.cuda.is_available())\n",
        "\n",
        "# Each validation dataset contains 3251 x 5 images.\n",
        "\n",
        "val_loader = DataLoader(\n",
        " ConcatDataset([ImageFolder(\n",
        "          params.IMG_VAL_PATH, \n",
        "          transform=tsf.base_transform),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=tsf.data_translate),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=tsf.data_grayscale),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=tsf.data_rotate),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=tsf.data_jitter_hue)]), \n",
        "          batch_size=1, \n",
        "          shuffle=False, num_workers=2, \n",
        "          pin_memory=torch.cuda.is_available())\n",
        "\n",
        "dataloaders_augment = {}\n",
        "dataloaders_augment['train'] = train_loader\n",
        "dataloaders_augment['val'] = val_loader\n",
        "\n",
        "print(\"Cumulative length of the train dataloaders:\", dataloaders_augment['train'].dataset.cumulative_sizes)\n",
        "print(\"Cumulative length of the val dataloaders:\", dataloaders_augment['val'].dataset.cumulative_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader.dataset.datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4mMvokoQMDY",
        "outputId": "08fb9b19-622e-43bd-e66c-6548252893aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Dataset ImageFolder\n",
              "     Number of datapoints: 3246\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            ), Dataset ImageFolder\n",
              "     Number of datapoints: 3246\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                RandomAffine(degrees=[-15.0, 15.0], translate=(0.1, 0.1))\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            ), Dataset ImageFolder\n",
              "     Number of datapoints: 3246\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                Grayscale(num_output_channels=3)\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            ), Dataset ImageFolder\n",
              "     Number of datapoints: 3246\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            ), Dataset ImageFolder\n",
              "     Number of datapoints: 3246\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                ColorJitter(brightness=None, contrast=None, saturation=None, hue=[-0.4, 0.4])\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            )]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader.dataset.datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKL_bclIOjl0",
        "outputId": "715ca03c-35b8-45b3-f739-d3c723415278"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Dataset ImageFolder\n",
              "     Number of datapoints: 8394\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            ), Dataset ImageFolder\n",
              "     Number of datapoints: 8394\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                RandomAffine(degrees=[-15.0, 15.0], translate=(0.1, 0.1))\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            ), Dataset ImageFolder\n",
              "     Number of datapoints: 8394\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                Grayscale(num_output_channels=3)\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            ), Dataset ImageFolder\n",
              "     Number of datapoints: 8394\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            ), Dataset ImageFolder\n",
              "     Number of datapoints: 8394\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: Compose(\n",
              "                Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "                ColorJitter(brightness=None, contrast=None, saturation=None, hue=[-0.4, 0.4])\n",
              "                ToTensor()\n",
              "                Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "            )]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloaders_augment['train'] # dataloader_obj\n",
        "single_dataset = dataloaders_augment['train'].dataset.datasets[1]\n",
        "single_dataset"
      ],
      "metadata": {
        "id": "EAetdxHrD-3K",
        "outputId": "8537041e-3e4e-4d3e-e20b-0e45ed5b34dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 8394\n",
              "    Root location: data/train\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)\n",
              "               RandomAffine(degrees=[-15.0, 15.0], translate=(0.1, 0.1))\n",
              "               ToTensor()\n",
              "               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
              "           )"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_single = DataLoader(single_dataset, \n",
        "    batch_size=1, shuffle=True, # note that batch size is 1, to make count work. \n",
        "    num_workers=2)"
      ],
      "metadata": {
        "id": "FIlIWyy_7z88"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2class = {v: k for k, v in single_dataset.class_to_idx.items()}\n",
        "\n",
        "def get_class_distribution_loader(dataloader_obj, dataset_obj):\n",
        "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
        "    \n",
        "    for _, j in dataloader_obj:\n",
        "        y_idx = j.item()\n",
        "        y_lbl = idx2class[y_idx]\n",
        "        count_dict[str(y_lbl)] += 1\n",
        "            \n",
        "    return count_dict"
      ],
      "metadata": {
        "id": "ctXIO4PVDyVj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_class_distribution_loader(train_loader_single, single_dataset)"
      ],
      "metadata": {
        "id": "vhP2C_DsEoqa",
        "outputId": "826f81fa-e9ab-4c12-91d8-dbc7e9159f81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 521,\n",
              " '1': 501,\n",
              " '2': 473,\n",
              " '3': 471,\n",
              " '4': 515,\n",
              " '5': 483,\n",
              " '6': 561,\n",
              " '7': 515,\n",
              " '8': 4354}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MQSBEJenM3mV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def delete_train_val_files(path):\n",
        "  for sub_dir in sorted(os.listdir(path)):\n",
        "    for file_name in os.listdir(os.path.join(path, sub_dir)):\n",
        "      file = os.path.join(path, sub_dir, file_name)\n",
        "      if os.path.isfile(file):\n",
        "        os.remove(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delete all files in Colab file system. "
      ],
      "metadata": {
        "id": "4kFCNZ4iRW6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_train_val_files(params.IMG_TRAIN_PATH)\n",
        "delete_train_val_files(params.IMG_VAL_PATH)\n",
        "\n"
      ],
      "metadata": {
        "id": "7yvcSt2jRNeN"
      },
      "execution_count": 16,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "load_deepweeds.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}