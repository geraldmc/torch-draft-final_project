{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geraldmc/torch-draft-final_project/blob/main/concat_exp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vEQjq5zCM3mT"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import time\n",
        "from datetime import datetime\n",
        "import glob \n",
        "import shutil\n",
        "import copy\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.data import RandomSampler, random_split\n",
        "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbxKpG6s9vK"
      },
      "source": [
        "### Download the code from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YZMmT0PtCog",
        "outputId": "583f47d7-1894-49ae-ad7b-68ac8949b746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading file...\n",
            "--2022-04-23 15:45:54--  https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main [following]\n",
            "--2022-04-23 15:45:54--  https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.114.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.114.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [  <=>               ]   3.01M  9.62MB/s    in 0.3s    \n",
            "\n",
            "2022-04-23 15:45:55 (9.62 MB/s) - ‘main.zip’ saved [3161009]\n",
            "\n",
            "/content/torch-draft-final_project-main\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.path.isfile(\"../main.zip\"):\n",
        "  print ('Have already downloaded the project file, continuing...')\n",
        "  print()\n",
        "else:\n",
        "  print ('Downloading file...')\n",
        "  ! wget https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
        "  ! unzip -qq main.zip\n",
        "  %cd torch-draft-final_project-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "80iS3idAM3mU"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  import conf.params as params\n",
        "  #from data import transforms as tsf\n",
        "except ImportError:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "print()\n",
        "print(\"Downloading DeepWeeds images to \" + params.IMG_ZIP_FILE)\n",
        "!cp '{params.GD_ZIP_IMG}' '{params.IMG_ZIP_FILE}'\n",
        "print()\n",
        "!ls -lart {params.IMG_ZIP_FILE}\n",
        "\n",
        "print()\n",
        "print(\"Downloading GAN images to \" + params.GAN_ZIP_FILE)\n",
        "!cp '{params.GD_ZIP_GAN}' '{params.GAN_ZIP_FILE}'\n",
        "print()\n",
        "!ls -lart {params.GAN_ZIP_FILE}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtEnDyb9NKSY",
        "outputId": "cab420d5-5c88-4ca1-9d89-4a44a1c0a5c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "\n",
            "Downloading DeepWeeds images to data/images.zip\n",
            "\n",
            "-rw------- 1 root root 491516047 Apr 23 15:46 data/images.zip\n",
            "\n",
            "Downloading GAN images to data/gans.zip\n",
            "\n",
            "-rw------- 1 root root 53284865 Apr 23 15:46 data/gans.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] Unzipping DeepWeeds images into \" +  params.IMG_DIRECTORY)\n",
        "\n",
        "with ZipFile(params.IMG_ZIP_FILE, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(params.IMG_DIRECTORY)\n",
        "\n",
        "img_list=os.listdir(params.IMG_DIRECTORY)\n",
        "print(len(img_list))\n",
        "\n",
        "print()\n",
        "print(\"[INFO] Unzipping GAN image dirs into \" + params.DATA_PATH)\n",
        "\n",
        "with ZipFile(params.GAN_ZIP_FILE, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(params.DATA_PATH)\n",
        "\n",
        "gan_dir_list=os.listdir(params.DATA_PATH+'/gans/train/0')\n",
        "print(len(gan_dir_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ifx_iZznNZyi",
        "outputId": "2db33af2-26d5-4641-b76e-6a4747efbb39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Unzipping DeepWeeds images into data/images\n",
            "17510\n",
            "\n",
            "[INFO] Unzipping GAN image dirs into data\n",
            "750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGBEIPMM3mU"
      },
      "source": [
        "### 1) Combine train, test, val files, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k5PGmGFeM3mU"
      },
      "outputs": [],
      "source": [
        "import glob \n",
        "\n",
        "joined_val = os.path.join(\"data/\", \"labels/\", \"val*.csv\")\n",
        "joined_train = os.path.join(\"data/\", \"labels/\", \"train*.csv\")\n",
        "joined_test = os.path.join(\"data/\", \"labels/\", \"test*.csv\")\n",
        "\n",
        "val_files = glob.glob(joined_val)\n",
        "train_files = glob.glob(joined_train)\n",
        "test_files = glob.glob(joined_test)\n",
        "\n",
        "train_df = pd.concat(map(pd.read_csv, train_files), ignore_index=True)\n",
        "val_df = pd.concat(map(pd.read_csv, val_files), ignore_index=True)\n",
        "test_df = pd.concat(map(pd.read_csv, test_files), ignore_index=True)\n",
        "\n",
        "# In the paper, each fold contains 10,505 samples from the total\n",
        "def sample_data(train_sample_no, val_sample_no, test_sample_no): \n",
        "    train = train_df.sample(n=train_sample_no)\n",
        "    val = val_df.sample(n=val_sample_no)\n",
        "    test = test_df.sample(n=test_sample_no)\n",
        "    return train, val, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SgMdUhWM3mV"
      },
      "source": [
        "### 2) Copy files to their respective directories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "82K5oW7oM3mV"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "files = []\n",
        "for dirpath, dirnames, filenames in os.walk(params.IMAGE_PATH):\n",
        "    for file in filenames:\n",
        "        files.append(file)\n",
        "\n",
        "def copy_files(df, filepath):\n",
        "\n",
        "  labels = dict(zip(df.Filename, df.Label)) \n",
        "  for f in files:\n",
        "      try:\n",
        "          src = os.path.join(params.IMG_DIRECTORY, f)\n",
        "          dst = os.path.join(filepath, str(labels[f]), f)\n",
        "          shutil.copyfile(src, dst)\n",
        "      except KeyError:\n",
        "          pass\n",
        "\n",
        "# sample number same as paper.\n",
        "sample_train_df = train_df.sample(n=10505)\n",
        "sample_val_df = val_df.sample(n=3502)\n",
        "sample_test_df = test_df.sample(n=3502) \n",
        "\n",
        "copy_files(sample_train_df, params.IMG_TRAIN_PATH)\n",
        "copy_files(sample_val_df, params.IMG_VAL_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/aleju/imgaug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7L6DF1B-B7Fj",
        "outputId": "226baa9a-3e1a-42d9-d285-382164681b0b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/aleju/imgaug\n",
            "  Cloning https://github.com/aleju/imgaug to /tmp/pip-req-build-ug3k5ryq\n",
            "  Running command git clone -q https://github.com/aleju/imgaug /tmp/pip-req-build-ug3k5ryq\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (3.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (0.18.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (4.1.2.30)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.8.1.post1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.6.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (3.0.8)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug==0.4.0) (4.1.1)\n",
            "Building wheels for collected packages: imgaug\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.4.0-py3-none-any.whl size=971122 sha256=822f823586c4626cff22e71a7b74ea78d43035b3c141f4dcd7d69a842bb95190\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gzze4xf6/wheels/24/09/69/f6547987407c2e85f9923e8e1189167fec80074ee5c6fe6ebd\n",
            "Successfully built imgaug\n",
            "Installing collected packages: imgaug\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed imgaug-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia"
      ],
      "metadata": {
        "id": "Kck1KTDpB3R2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImgAugTransform:\n",
        "  def __init__(self):\n",
        "    self.aug = iaa.Sequential([\n",
        "        iaa.Resize((224, 224)),\n",
        "        iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
        "        iaa.Fliplr(0.5),\n",
        "        iaa.Affine(rotate=(-20, 20), mode='symmetric'),\n",
        "        iaa.Sometimes(0.25,\n",
        "                      iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
        "                                 iaa.CoarseDropout(0.1, size_percent=0.5)])),\n",
        "        iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
        "    ])\n",
        "      \n",
        "  def __call__(self, img):\n",
        "    img = np.array(img)\n",
        "    return self.aug.augment_image(img)\n",
        "\n",
        "transforms = ImgAugTransform()"
      ],
      "metadata": {
        "id": "XOVs-HMtB0EE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNrM2EqkM3mV"
      },
      "source": [
        "### 3) Instantiate the data loaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo4BHFQgM3mV",
        "outputId": "b37b5096-f52a-4fac-9144-9242c0377d7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cumulative length of the train dataloaders: [8416, 16832, 25248, 33664, 42080]\n",
            "Cumulative length of the val dataloaders: [3257, 6514, 9771, 13028, 16285]\n"
          ]
        }
      ],
      "source": [
        "#from data import transforms as tsf\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Each training dataset contains 8382 x 5 images.\n",
        "\n",
        "train_loader = DataLoader(\n",
        " ConcatDataset([ImageFolder(\n",
        "          params.IMG_TRAIN_PATH, \n",
        "          transform=transforms),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=transforms),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=transforms),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=transforms),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=transforms)]), \n",
        "          batch_size=1, \n",
        "          shuffle=True, num_workers=2, \n",
        "          pin_memory=torch.cuda.is_available())\n",
        "\n",
        "# Each validation dataset contains 3251 x 5 images.\n",
        "\n",
        "val_loader = DataLoader(\n",
        " ConcatDataset([ImageFolder(\n",
        "          params.IMG_VAL_PATH, \n",
        "          transform=transforms),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=transforms),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=transforms),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=transforms),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=transforms)]), \n",
        "          batch_size=1, \n",
        "          shuffle=False, num_workers=2, \n",
        "          pin_memory=torch.cuda.is_available())\n",
        "\n",
        "dataloaders_augment = {}\n",
        "dataloaders_augment['train'] = train_loader\n",
        "dataloaders_augment['val'] = val_loader\n",
        "\n",
        "print(\"Cumulative length of the train dataloaders:\", dataloaders_augment['train'].dataset.cumulative_sizes)\n",
        "print(\"Cumulative length of the val dataloaders:\", dataloaders_augment['val'].dataset.cumulative_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_loader.dataset.datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4mMvokoQMDY",
        "outputId": "6522c28f-db9b-4ef5-cce4-831406439f6a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Dataset ImageFolder\n",
              "     Number of datapoints: 3257\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>,\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 3257\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>,\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 3257\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>,\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 3257\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>,\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 3257\n",
              "     Root location: data/val\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader.dataset.datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKL_bclIOjl0",
        "outputId": "f5d028a5-1b76-45df-b5b0-023c65b9590f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Dataset ImageFolder\n",
              "     Number of datapoints: 8416\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>,\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 8416\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>,\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 8416\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>,\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 8416\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>,\n",
              " Dataset ImageFolder\n",
              "     Number of datapoints: 8416\n",
              "     Root location: data/train\n",
              "     StandardTransform\n",
              " Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dataloaders_augment['train'] # dataloader_obj\n",
        "single_dataset = dataloaders_augment['train'].dataset.datasets[1]\n",
        "single_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAetdxHrD-3K",
        "outputId": "25d0ea5e-5e18-45d4-d7db-ae7953047f8a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 8416\n",
              "    Root location: data/train\n",
              "    StandardTransform\n",
              "Transform: <__main__.ImgAugTransform object at 0x7f53b09e4b10>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader_single = DataLoader(single_dataset, \n",
        "    batch_size=1, shuffle=True, # note that batch size is 1, to make count work. \n",
        "    num_workers=2)"
      ],
      "metadata": {
        "id": "FIlIWyy_7z88"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2class = {v: k for k, v in single_dataset.class_to_idx.items()}\n",
        "\n",
        "def get_class_distribution_loader(dataloader_obj, dataset_obj):\n",
        "    count_dict = {k:0 for k,v in dataset_obj.class_to_idx.items()}\n",
        "    \n",
        "    for _, j in dataloader_obj:\n",
        "        y_idx = j.item()\n",
        "        y_lbl = idx2class[y_idx]\n",
        "        count_dict[str(y_lbl)] += 1\n",
        "            \n",
        "    return count_dict"
      ],
      "metadata": {
        "id": "ctXIO4PVDyVj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_class_distribution_loader(train_loader_single, single_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhP2C_DsEoqa",
        "outputId": "9f962b79-318f-4437-f9de-156fbf776196"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 515,\n",
              " '1': 543,\n",
              " '2': 519,\n",
              " '3': 508,\n",
              " '4': 507,\n",
              " '5': 479,\n",
              " '6': 500,\n",
              " '7': 481,\n",
              " '8': 4364}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "MQSBEJenM3mV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def delete_train_val_files(path):\n",
        "  for sub_dir in sorted(os.listdir(path)):\n",
        "    for file_name in os.listdir(os.path.join(path, sub_dir)):\n",
        "      file = os.path.join(path, sub_dir, file_name)\n",
        "      if os.path.isfile(file):\n",
        "        os.remove(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Delete all files in Colab file system. "
      ],
      "metadata": {
        "id": "4kFCNZ4iRW6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "delete_train_val_files(params.IMG_TRAIN_PATH)\n",
        "delete_train_val_files(params.IMG_VAL_PATH)\n",
        "\n"
      ],
      "metadata": {
        "id": "7yvcSt2jRNeN"
      },
      "execution_count": 19,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "load_deepweeds.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}