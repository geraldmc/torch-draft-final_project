{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/geraldmc/torch-draft-final_project/blob/main/load_deepweeds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os \n",
        "import time\n",
        "from datetime import datetime\n",
        "import glob \n",
        "import shutil\n",
        "import copy\n",
        "from zipfile import ZipFile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torch.utils.data import RandomSampler, random_split\n",
        "from torch.utils.data import SubsetRandomSampler, WeightedRandomSampler\n",
        "from torchvision.datasets import ImageFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pbxKpG6s9vK"
      },
      "source": [
        "### Download the code from Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YZMmT0PtCog",
        "outputId": "7b990a66-048a-4e99-b36f-53e6b6171540"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading file...\n",
            "--2022-03-29 22:06:09--  https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main [following]\n",
            "--2022-03-29 22:06:09--  https://codeload.github.com/geraldmc/torch-draft-final_project/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 52.193.111.178\n",
            "Connecting to codeload.github.com (codeload.github.com)|52.193.111.178|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [ <=>                ] 526.76K  2.65MB/s    in 0.2s    \n",
            "\n",
            "2022-03-29 22:06:11 (2.65 MB/s) - ‘main.zip’ saved [539403]\n",
            "\n",
            "/content/torch-draft-final_project-main\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if os.path.isfile(\"../main.zip\"):\n",
        "  print ('Have already downloaded the project file, continuing...')\n",
        "  print()\n",
        "else:\n",
        "  print ('Downloading file...')\n",
        "  ! wget https://github.com/geraldmc/torch-draft-final_project/archive/refs/heads/main.zip\n",
        "  ! unzip -qq main.zip\n",
        "  %cd torch-draft-final_project-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "  import conf.params as params\n",
        "  from data import transforms as tsf\n",
        "except ImportError:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1) Combine all train, test, val files, and random sample from the combined dataframes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob \n",
        "\n",
        "joined_val = os.path.join(\"data/\", \"labels/\", \"val*.csv\")\n",
        "joined_train = os.path.join(\"data/\", \"labels/\", \"train*.csv\")\n",
        "joined_test = os.path.join(\"data/\", \"labels/\", \"test*.csv\")\n",
        "\n",
        "val_files = glob.glob(joined_val)\n",
        "train_files = glob.glob(joined_train)\n",
        "test_files = glob.glob(joined_test)\n",
        "\n",
        "train_df = pd.concat(map(pd.read_csv, train_files), ignore_index=True)\n",
        "val_df = pd.concat(map(pd.read_csv, val_files), ignore_index=True)\n",
        "test_df = pd.concat(map(pd.read_csv, test_files), ignore_index=True)\n",
        "\n",
        "# In the paper, each fold contains 10,505 samples from the total\n",
        "def sample_data(train_sample_no, val_sample_no, test_sample_no): \n",
        "    train = train_df.sample(n=train_sample_no)\n",
        "    val = val_df.sample(n=val_sample_no)\n",
        "    test = test_df.sample(n=test_sample_no)\n",
        "    return train, val, test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2) Copy files to their respective directories, for ImageFolder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "files = []\n",
        "for dirpath, dirnames, filenames in os.walk(params.IMAGE_PATH):\n",
        "    for file in filenames:\n",
        "        files.append(file)\n",
        "\n",
        "def copy_files(df, filepath):\n",
        "\n",
        "  labels = dict(zip(df.Filename, df.Label)) \n",
        "  for f in files:\n",
        "      try:\n",
        "          src = os.path.join(params.IMG_DIRECTORY, f)\n",
        "          dst = os.path.join(filepath, str(labels[f]), f)\n",
        "          shutil.copyfile(src, dst)\n",
        "      except KeyError:\n",
        "          pass\n",
        "\n",
        "# sample number same as paper.\n",
        "sample_train_df = train_df.sample(n=10505)\n",
        "sample_val_df = val_df.sample(n=3502)\n",
        "sample_test_df = test_df.sample(n=3502) \n",
        "\n",
        "copy_files(sample_train_df, params.IMG_TRAIN_PATH)\n",
        "copy_files(sample_val_df, params.IMG_VAL_PATH)\n",
        "copy_files(label_df, params.IMG_CLASSES) # this holds all unsegregatd files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3) Instantiate the data loaders for this k-fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from data import transforms as tsf\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Each training dataset contains 8382 x 5 images.\n",
        "\n",
        "train_loader = DataLoader(\n",
        " ConcatDataset([ImageFolder(\n",
        "          params.IMG_TRAIN_PATH, \n",
        "          transform=tsf.base_transform),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=tsf.data_translate),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=tsf.data_grayscale),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=tsf.data_rotate),\n",
        "     ImageFolder(\n",
        "          params.IMG_TRAIN_PATH,\n",
        "          transform=tsf.data_jitter_hue)]), \n",
        "          batch_size=32, \n",
        "          shuffle=True, num_workers=2, \n",
        "          pin_memory=torch.cuda.is_available())\n",
        "\n",
        "# Each validation dataset contains 3251 x 5 images.\n",
        "\n",
        "val_loader = DataLoader(\n",
        " ConcatDataset([ImageFolder(\n",
        "          params.IMG_VAL_PATH, \n",
        "          transform=tsf.base_transform),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=tsf.data_translate),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=tsf.data_grayscale),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=tsf.data_rotate),\n",
        "     ImageFolder(\n",
        "          params.IMG_VAL_PATH,\n",
        "          transform=tsf.data_jitter_hue)]), \n",
        "          batch_size=32, \n",
        "          shuffle=False, num_workers=2, \n",
        "          pin_memory=torch.cuda.is_available())\n",
        "\n",
        "dataloaders_augment = {}\n",
        "dataloaders_augment['train'] = train_loader\n",
        "dataloaders_augment['val'] = val_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def delete_class_files(path):\n",
        "  for file_name in os.listdir(path):\n",
        "      file = path + file_name\n",
        "      #print(file)\n",
        "      if os.path.isfile(file):\n",
        "          os.remove(file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNakgWdfr0oHr8HQcRFOsFM",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "load_deepweeds.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
